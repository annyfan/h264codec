# -*- coding: utf-8 -*-
"""upload data to huggingface.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UsJp_Ei1sxP6yew-dREsjR4QeVrvMe_y

## data loaders
"""

from typing import Any, List
from torch.utils.data.sampler import Sampler
import csv
import logging
import random
from functools import partial
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import torch
import torchvision
from PIL import Image
from torch.utils import data
from torch.utils.data import DataLoader, SubsetRandomSampler

from tqdm import tqdm
import datasets
import os
class SubsetSequentialSampler(Sampler):
    """Samples elements sequentially from a given list of indices, inspired by
    torch.utils.data.sampler.SubsetRandomSampler"""

    def __init__(self, indices: List[int]) -> None:
        """
        Class initialization.

        Args:
           indices:
               The list of indices used by the sequential sampler.
        """
        self.indices = indices

    def __iter__(self):
        """
        Iterator using internal list of indices.

        Returns:
            An iterator in the internal list.
        """
        return iter(self.indices)

    def __len__(self):
        """
        Length of indices.

        Returns:
            Returns the number of elements in the list.
        """
        return len(self.indices)




def seed_worker(workerId: int) -> None:
    """Method for random values initialization in the dataloader. The argument list is fixed.

    Args:
        workerId: worker id.
    """
    workerSeed = torch.initial_seed() % 2 ** 32
    np.random.seed(workerSeed)
    random.seed(workerSeed)

def create_dataset(config: dict, evaluate: bool = False) -> "H264Data":
    """
    Utility function for the creation of a data loader, including
    loundness data, data normalization and transformation.

    Args:
        config:
            The dictionary with the application configuration.

    Returns:
        The HypeData data loader.
    """
    image_size = (config["dataset"]["img_size"][0], config["dataset"]["img_size"][1])


    if evaluate:
        imgTransform = torchvision.transforms.Compose(
            [
                torchvision.transforms.Resize(image_size),
                torchvision.transforms.ToTensor(),
            ]
        )
    else:
        imgTransform = torchvision.transforms.Compose(
            [
                torchvision.transforms.Resize(image_size),
                torchvision.transforms.ToTensor(),
            ]
        )

    # Data tranformation.
    dataset = H264Data(config, imgTransform)

    return dataset


def set_dataloader(
    config: dict,
    dataset: "H264Data",
) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """Create the DataLoaders for training, validation and testing.

    Args:
        config:
            The dictionary with the application configuration.
        dataset:
            The deeplake dataset for training.

    Returns:
        A tuple of dataloaders (for training, validation and testing).
    """
    # Determine the type of sampler based on the configuration name. Invalid strings will trigger
    # a logger error with full stack information.
    if config["train"].get("sampler", "Random") == "Random":
        selsampler = SubsetRandomSampler
    elif config["train"].get("sampler", "Sequential") == "Sequential":
        selsampler = SubsetSequentialSampler
    else:
        selsampler = SubsetRandomSampler

    trainLoader = DataLoader(
        dataset,
        batch_size=config["train"]["batch_size"],
        sampler=selsampler(dataset.get_indices("TRAIN")),
        num_workers=config["train"]["num_workers"],
        worker_init_fn=seed_worker,
        pin_memory=True,
        #collate_fn=partial(byteformer_h264_collate_fn, config=config),
    )
    valLoader = DataLoader(
        dataset,
        batch_size=config["train"]["batch_size"],
        sampler=selsampler(dataset.get_indices("VALIDATE")),
        num_workers=config["train"]["num_workers"],
        worker_init_fn=seed_worker,
        pin_memory=True,
        #collate_fn=partial(byteformer_h264_collate_fn, config=config),
    )
    testLoader = DataLoader(
        dataset,
        batch_size=config["train"]["batch_size_test"],
        sampler=selsampler(dataset.get_indices("TEST")),
        num_workers=1,
        worker_init_fn=seed_worker,
        pin_memory=True,
        #collate_fn=partial(byteformer_h264_collate_fn, config=config),
    )

    return trainLoader, valLoader, testLoader


def make_dataset(datasetNames: List[str], config: dict) -> Dict[str, List[str]]:
    """
    Parse the dataset files and create the list of files, detection and poses.
    """
    data = {
        "id": [],
        "dataset": [],
        "trainIndices": [],
        "testIndices": [],
        "valIndices": [],
    }

    index = 0
    for dataset in datasetNames:
        traintest =  config["dataset"].get("traintest", [])
        validtest =  config["dataset"].get("validtest", [])
        datasetcsv = config["dataset"].get("datasetcsv", "dataset.csv")
        with open(Path(config["dataset"]["base_dir"]) / dataset / datasetcsv) as f:
            reader = csv.reader(f)
            next(reader, None)  # skip the headers
            for row in reader:
                data["dataset"].append(dataset)
                data["id"].append(row[0])

                trainFlag = row[1]
                if trainFlag == "TRAIN":
                    data["trainIndices"].append(index)
                elif trainFlag == "VALIDATE":
                    data["valIndices"].append(index)
                elif trainFlag == "TEST":
                    data["testIndices"].append(index)
                else:
                    raise ValueError("Invalid training flag."+ trainFlag)

                if traintest is not None and row[0] in traintest:
                    data["testIndices"].append(index)
                if validtest is not None and row[0] in validtest:
                    data["testIndices"].append(index)

                index += 1

    return data


def image_loader(imgPath: Path):
    """
    Image dataloader from a file path and an alpha mask.

    Parameters
    ----------
    imgPath : string
        The full file path to the image.

    Returns
    -------
    The RGB image array.
    """
    img = Image.open(imgPath).convert("RGB")

    return img


def h264_loader(h264Path: Path):
    """
    TBD
    """
    
    h264 = torchvision.io.read_file(str(h264Path))
    return h264


class H264Data(data.Dataset):
    """Dataset class for loading the loudness data, given an index."""

    def __init__(
            self,
            config: dict,
            imgTransform: torchvision.transforms.Compose,
    ):
        """
        HypeData constructor.

        Args:
            config (dict):
                The application configuration dictionary.
            imgNormalize:
                The functor used to transform/normalize the model features.
            imgTransform:
                The functor used to transform/normalize the model features.

        Raises:
            ValueError: a value exception is raised if the training flag is invalid.
        """
        self.cfg = config

        # Get the data from the configuration files.
        datasetNames = [
            f"{self.cfg['dataset']['base_name']}_{name}"
            for name in self.cfg["dataset"]["versions"]
        ]
        self.dataset = make_dataset(datasetNames, config)

        # Data transformation (e.g. normalization)
        self.imgTransform = imgTransform
        self.h264PaddedSeqLen = config["dataset"].get("h264_padded_seq_len", None)

        # Base path
        self.basePath = Path(config["dataset"]["base_dir"])
        self.baseName = Path(config["dataset"]["base_name"])

    def get_indices(self, phase) -> List[int]:
        """
        Utility for getting a list of all indices, based on the phase id. A shuffle option is
        available for the training/validation phase.

        Args:
            phase:
                The training phase enumerated value.

        Returns:
           The list of indices for either the train/validate or test phases.
        """
        if phase == "TRAIN":
            return self.dataset["trainIndices"]
        if phase == "VALIDATE":
            return self.dataset["valIndices"]
        if phase == "TEST":
            return self.dataset["testIndices"]

        raise ValueError

    def __getitem__(self, index: int) -> dict:
        """Get an item at a given index in dataset.

        Args:
            index:
                The list index for the dataset.

        Returns:
            A dictionary of values for training and testing.
        """
        # Load images
        imageFilename = (
                self.basePath
                / f"{self.dataset['dataset'][index]}"
                / "image"
                / f"{self.dataset['id'][index]}.jpeg"
        )
        image = self.imgTransform(image_loader(imageFilename))

        # Load h264
        h264Filename = (
                self.basePath
                / f"{self.dataset['dataset'][index]}"
                / "h264"
                / f"{self.dataset['id'][index]}.h264"
        )
        h264 = h264_loader(h264Filename)

        return {
            "image": image,
            "h264":  h264,
            "id": self.dataset["id"][index],
            "size": h264.shape[0]
        }

    def __len__(self) -> int:
        """Return size (num. entries) of the dataset.

        Returns:
           The total number of dataset elements.
        """

        return len(self.dataset["id"])

"""## upload data

!pip install datasets
!pip install huggingface_hub

"""

def gen(dataloader):
    loaderIter = iter(dataloader)
    for loadedData in tqdm(loaderIter):
        yield loadedData  # this has to be a dictionary



def upload(config: dict) -> None:
    """
    Setup before calling the training function.

    Args:
        configPath (str): the path to the yaml configuration file.
        baseDir (str): the reference directory for the configuration links.
    """

    # Create a dataset.
    dataset = create_dataset(config)

    # Get the dataset loaders.
    trainLoader, valLoader, testLoader = set_dataloader(config, dataset)

    
    #val_dataset = datasets.Dataset.from_generator(gen, gen_kwargs={"dataloader": valLoader})
    #val_dataset.push_to_hub("BotniVision/h264_images", split="validation", token="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") #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
    #print(train_dataset[0]["id"])
    train_dataset = datasets.Dataset.from_generator(gen, gen_kwargs={"dataloader": trainLoader})
    train_dataset.push_to_hub("BotniVision/h264_images", split="train", token="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")
   

if __name__ == "__main__":
    config ={ "dataset":{"img_size":[64, 64], "versions":[ "v20231127","v20240206_1", "v20240206_2", "v20240206_3","v20240206_4","v20240206_5","v20240206_6","v20240206_7"], "base_name": "h264", "base_dir":"C:\\tmp\\dataset\\"},
            "train":{"batch_size":1, "num_workers":1, "batch_size_test":1}
    }
    upload(config)

